{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeTUOfSQSHPD"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Copyright 2024 Nicol√≤ Marchini\n",
        "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "   you may not use this file except in compliance with the License.\n",
        "   You may obtain a copy of the License at\n",
        "\n",
        "       http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "   Unless required by applicable law or agreed to in writing, software\n",
        "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "   See the License for the specific language governing permissions and\n",
        "   limitations under the License.\n",
        "'''\n",
        "\n",
        "# This file is a modified version of https://github.com/anonym-user-35/rethinking-ml-models/blob/master/value_analysis_binary.ipynb\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRR7zEtDa2y0"
      },
      "outputs": [],
      "source": [
        "#This notebook is created to run value analysis with your own model on binary datasets\n",
        "#specify the required info here and run the notebook to receive value analysis result for your model\n",
        "modelName = 'name_of_your_model'\n",
        "resPath = 'define_the_path_for_results'\n",
        "data_folder = 'define_the_path_where_you_keep_the_confidence_values_of_your_model_and_the_datasets'\n",
        "confidencesToVal = 'name_of_the_numpy_array_for_the_confidences_on_validation_set.npy'\n",
        "dataToVal = 'name_of_validation_set.csv'\n",
        "confidencesToTest = 'name_of_the_numpy_array_for_the_confidences_on_test_set.npy'\n",
        "dataToTest ='name_of_test_set.csv'\n",
        "ground_truth_column = 'specify_the_column_for_ground_truth_in_your_csv_files'\n",
        "txt = 'specify_the_column_for_text_in_your_csv_files'\n",
        "datasetName = 'name_of_your_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK1wDvSfSiwx"
      },
      "outputs": [],
      "source": [
        "def cost_based_threshold(k):\n",
        "    \"\"\"calculate theoretical thresold\n",
        "\n",
        "    Args:\n",
        "        k (float):  how many times higher the abs value of an error is compared to a correct answer\n",
        "\n",
        "    Returns:\n",
        "        float: returns the optimal thresold given the cost\n",
        "    \"\"\"\n",
        "    t = (k) / (k + 1)\n",
        "    return t\n",
        "\n",
        "def calculate_value(y_hat_proba, y, t_fp, V_fp, t_fn, V_fn, Vc, Vr):\n",
        "    \"\"\" calculate value of classificator\n",
        "\n",
        "    Args:\n",
        "        y_hat_proba (2D npy array of float): contains confidences score on the set\n",
        "        y (1D npy array of 0 or 1): contains ground truth of the set\n",
        "        t_fp (float): thresold for false positive\n",
        "        V_fp (float): value of FP\n",
        "        t_fn (float): thresold for false negative\n",
        "        V_fn (float): value of FN\n",
        "        Vc (float): value of correct classification\n",
        "        Vr (float): value of reject classification\n",
        "\n",
        "    Returns:\n",
        "        float: value of classificator \n",
        "        int: number of rejected samples\n",
        "        int: number of wrong predictions\n",
        "        int: number of correct predictions\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    values = [Vc, V_fp, V_fn]\n",
        "    n_samples = len(y)\n",
        "    value_vector = np.full(n_samples, Vr)\n",
        "\n",
        "    # if any threshold is below 0.5 we need to make an extra check to assure that we are considering the most confident prediction\n",
        "    if ((t_fp < 0.5) or (t_fn < 0.5)):\n",
        "        # conditions to decide the value of the prediction\n",
        "        cond1 = (((y == 1) & (y_hat_proba[:, 1] > t_fp) & (y_hat_proba[:, 1] > y_hat_proba[:, 0])) | ((y == 0) & (y_hat_proba[:, 0] > t_fn)) & (y_hat_proba[:, 0] > y_hat_proba[:, 1]))\n",
        "        cond2 = (y_hat_proba[:, 1] > y_hat_proba[:, 0]) & (y != 1) & (y_hat_proba[:, 1] > t_fp)\n",
        "        cond3 = (y_hat_proba[:, 0] > y_hat_proba[:, 1]) & (y != 0) & (y_hat_proba[:, 0] > t_fn)\n",
        "\n",
        "        # Assigns the correct value to each prediction\n",
        "        value_vector[cond1] = values[0]\n",
        "        value_vector[cond2] = values[1]\n",
        "        value_vector[cond3] = values[2]\n",
        "\n",
        "    else:\n",
        "        # conditions to decide the value of the prediction\n",
        "        cond1 = ((y == 1) & (y_hat_proba[:, 1] > t_fp)) | ((y == 0) & (y_hat_proba[:, 0] > t_fn))\n",
        "        cond2 = (y != 1) & (y_hat_proba[:, 1] > t_fp)\n",
        "        cond3 = (y != 0) & (y_hat_proba[:, 0] > t_fn)\n",
        "\n",
        "        # Assigns the correct value to each prediction\n",
        "        value_vector[cond1] = values[0]\n",
        "        value_vector[cond2] = values[1]\n",
        "        value_vector[cond3] = values[2]\n",
        "\n",
        "    # Calculate the total value\n",
        "    value = np.sum(value_vector) / n_samples\n",
        "\n",
        "    # Calculate the number of rejected samples, wrong predictions, and correct predictions\n",
        "    numOfWrongPredictions = len(value_vector[cond2])+len(value_vector[cond3])\n",
        "    numOfCorrectPredictions = len(value_vector[cond1])\n",
        "    numOfRejectedSamples = n_samples - numOfCorrectPredictions - numOfWrongPredictions\n",
        "\n",
        "    return value, numOfRejectedSamples, numOfWrongPredictions, numOfCorrectPredictions\n",
        "\n",
        "def calculate_value_without_rejection(y_hat_proba, y, V_fp, V_fn, Vc):\n",
        "    \"\"\" calculate value of classificator assuming rejection is not allowed\n",
        "\n",
        "    Args:\n",
        "        y_hat_proba (2D npy array of float): contains confidences score on the set\n",
        "        y (1D npy array of 0 or 1): contains ground truth of the set\n",
        "        V_fp (float): value of FP\n",
        "        V_fn (float): value of FN\n",
        "        Vc (float): value of correct classification\n",
        "\n",
        "    Returns:\n",
        "        float: value of classificator \n",
        "        int: number of wrong samples\n",
        "        int: number of correct predictions\n",
        "\n",
        "    \"\"\"\n",
        "    values = [V_fp, V_fn]\n",
        "    n_samples = len(y)\n",
        "    value_vector = np.full(n_samples, Vc)\n",
        "\n",
        "    # conditions to decide the value of the prediction\n",
        "    cond1 = (y != 1) & (y_hat_proba[:, 1] > y_hat_proba[:, 0])\n",
        "    cond2 = (y != 0) & (y_hat_proba[:, 0] > y_hat_proba[:, 1])\n",
        "\n",
        "    # Assigns the correct value to each prediction\n",
        "    value_vector[cond1] = values[0]\n",
        "    value_vector[cond2] = values[1]\n",
        "    \n",
        "    # Calculate the total value\n",
        "    value = np.sum(value_vector) / n_samples\n",
        "\n",
        "    # Calculate the number of wrong predictions and correct predictions\n",
        "    numOfWrongPredictions = len(value_vector[cond1])+len(value_vector[cond2])\n",
        "    numOfCorrectPredictions = n_samples-numOfWrongPredictions\n",
        "\n",
        "    return value, numOfWrongPredictions, numOfCorrectPredictions\n",
        "\n",
        "def find_optimum_confidence_threshold_fp(y_hat_proba, y, theoretical, Vw_fp, Vc, Vr, confidence, precision):\n",
        "    \"\"\" calculates the best empirical t_fp given a precision and a confidence\n",
        "\n",
        "    Args:\n",
        "        y_hat_proba (2D npy array of float): contains confidences score on the set\n",
        "        y (1D npy array of 0 or 1): contains ground truth of the set\n",
        "        theoretical (float): contains the middle point of the search, good estimate would be the \n",
        "                             theoretical threshold\n",
        "        Vw_fp (float): value of FP\n",
        "        Vc (float): value of correct classification\n",
        "        confidence (float): how far from the middle point to search, 1 is equal to searching the whole [0,1] range,\n",
        "                            should be positive\n",
        "        precision (int): number of decimal numbers of the step to iterate inside the [0,1] range, \n",
        "                         1 means a step of 0.1, should be positive \n",
        "    Returns:\n",
        "        float: best empirical t_fp given a precision and a confidence\n",
        "\n",
        "    \"\"\"\n",
        "    #initialize\n",
        "    max_value=float('-inf')\n",
        "    max_t_fp = 0\n",
        "    step = 10 ** -precision\n",
        "    # rounds to be consistent\n",
        "    theoretical=round(theoretical,precision)\n",
        "    # iterates over all values of t_fp within a confidence range of the theoretical threshold with a step\n",
        "    for t_fp in np.arange(max(theoretical-confidence,0), min(theoretical+confidence+step,1+step), step):\n",
        "        value,_,_,_ = calculate_value(y_hat_proba, y, t_fp, Vw_fp, 0.6, 0, Vc, Vr)\n",
        "        #if value is higher select new best threshold\n",
        "        if(max_value<value):\n",
        "            max_value=value\n",
        "            max_t_fp=t_fp\n",
        "    return max_t_fp\n",
        "\n",
        "def find_optimum_confidence_threshold_fn(y_hat_proba, y, theoretical, Vw_fn, Vc, Vr, confidence, precision):\n",
        "    \"\"\" calculates the best empirical t_fn given a precision and a confidence\n",
        "\n",
        "    Args:\n",
        "        y_hat_proba (2D npy array of float): contains confidences score on the set\n",
        "        y (1D npy array of 0 or 1): contains ground truth of the set\n",
        "        theoretical (float): contains the middle point of the search, good estimate would be the \n",
        "                             theoretical threshold\n",
        "        Vw_fn (float): value of FN\n",
        "        Vc (float): value of correct classification\n",
        "        confidence (float): how far from the middle point to search, 1 is equal to searching the whole [0,1] range,\n",
        "                            should be positive\n",
        "        precision (int): number of decimal numbers of the step to iterate inside the [0,1] range, \n",
        "                         1 means a step of 0.1, should be positive \n",
        "    Returns:\n",
        "        float: best empirical t_fn given a precision and a confidence\n",
        "\n",
        "    \"\"\"\n",
        "    #initialize\n",
        "    max_value=float('-inf')\n",
        "    max_t_fn=0\n",
        "    step = 10 ** -precision\n",
        "    # rounds to be consistent\n",
        "    theoretical=round(theoretical,precision)\n",
        "    # iterates over all values of t_fn within a confidence range of the theoretical threshold with a step\n",
        "    for t_fn in np.arange(max(theoretical-confidence,0), min(theoretical+confidence+step,1+step), step):\n",
        "        value,_,_,_ = calculate_value(y_hat_proba, y, 0.6, 0, t_fn, Vw_fn, Vc, Vr)\n",
        "        #if value is higher select new best threshold\n",
        "        if(max_value<value):\n",
        "            max_value=value\n",
        "            max_t_fn=t_fn\n",
        "    return max_t_fn\n",
        "\n",
        "def cost_based_analysis(\n",
        "    y_hat_proba_val,\n",
        "    y_val,\n",
        "    y_hat_proba_test,\n",
        "    y_test,\n",
        "    res_path,\n",
        "    logfile_name,\n",
        "    Vr,\n",
        "    Vc,\n",
        "    Vw_list_fp,\n",
        "    Vw_list_fn,\n",
        "    precision_fp,\n",
        "    precision_fn,\n",
        "    confidence_fp,\n",
        "    confidence_fn,\n",
        "):\n",
        "    \"\"\" creates a file containing the value of a series of predictions using both a theoretical \n",
        "    and an empirically found perfect threshold for all the different error costs combinations \n",
        "\n",
        "    Args:\n",
        "        y_hat_proba_val (2D npy array of float): contains confidences score on the validation set\n",
        "        y_val (1D npy array of 0 or 1): contains ground truth of the validation set\n",
        "        y_hat_proba_test (2D npy array of float): contains confidences score on the test set\n",
        "        y_test (1D npy array of 0 or 1): contains ground truth of the test set\n",
        "        res_path (str): directory in which to print the file\n",
        "        logfile_name (str): name of result file\n",
        "        Vc (float): value of correct classification\n",
        "        Vr (float): value of reject classification\n",
        "        Vw_list_fp (list of float): list of values of FP error\n",
        "        Vw_list_fn (list of float): list of values of FN error\n",
        "        precision_fp (int): precision to use when searching for empirical threshold fp\n",
        "        precision_fn (int): precision to use when searching for empirical threshold fn\n",
        "        confidence_fp (float): confidence to use when searching for empirical threshold fp\n",
        "        confidence_fn (float): confidence to use when searching for empirical threshold fn\n",
        "    \"\"\"\n",
        "    # create log file\n",
        "    os.makedirs(os.path.join(os.getcwd(), res_path),exist_ok=True)\n",
        "    rc_path = os.path.join(os.getcwd(), res_path, logfile_name + \"_costBased_test.csv\")\n",
        "    with open(rc_path, \"w\") as f:\n",
        "        c = \"Vr,Vc,Vw_fp,Vw_fn,k_fp,k_fn,t_fp,t_fn,value,rejected,wrong,correct,t_optimal_fp,t_optimal_fn,value_optimal,rejected_opt,wrong_opt,correct_opt,value_no_rej,wrong_no_rej,correct_no_rej\"\n",
        "        f.write(c + \"\\n\")\n",
        "\n",
        "    # pre-compute all theoretical thresholds for each FN value\n",
        "    fn_list=[]\n",
        "    for Vw_fn in Vw_list_fn:\n",
        "        # calculate theoretical threshold\n",
        "        k_fn = (-1) * (Vw_fn / Vc)\n",
        "        t_fn = cost_based_threshold(k_fn)\n",
        "        # calculate empirically perfect threshold\n",
        "        fn_list.append((find_optimum_confidence_threshold_fn(\n",
        "            y_hat_proba_val, y_val, t_fn, Vw_fn, Vc, Vr, confidence_fn, precision_fn\n",
        "        ),t_fn,Vw_fn))\n",
        "\n",
        "    # iterates over all possible values for FP\n",
        "    for Vw_fp in Vw_list_fp:\n",
        "        data_log = []\n",
        "        \n",
        "        # calculate theoretical threshold\n",
        "        k_fp = (-1) * (Vw_fp / Vc)\n",
        "        t_fp = cost_based_threshold(k_fp)\n",
        "        \n",
        "        # calculate empirically perfect threshold\n",
        "        e_fp = find_optimum_confidence_threshold_fp(\n",
        "                y_hat_proba_val, y_val, t_fp, Vw_fp, Vc, Vr, confidence_fp, precision_fp\n",
        "            )\n",
        "        \n",
        "        for e_fn,t_fn,Vw_fn in fn_list:\n",
        "            #calculate value using theoretical best threshold\n",
        "            value_test, rej_test, wrong_test, correct_test = calculate_value(\n",
        "                y_hat_proba_test, y_test, e_fp, Vw_fp, t_fn, Vw_fn, Vc, Vr\n",
        "            )\n",
        "            \n",
        "            #calculate value using empirical perfect threshold\n",
        "            value_test_opt, rej_test_opt, wrong_test_opt, correct_test_opt = calculate_value(\n",
        "                y_hat_proba_test,\n",
        "                y_test,\n",
        "                e_fp,\n",
        "                Vw_fp,\n",
        "                e_fn,\n",
        "                Vw_fn,\n",
        "                Vc,\n",
        "                Vr,\n",
        "            )\n",
        "\n",
        "            # calculate value assuming no rejection\n",
        "            value_test_no_rej, wrong_test_no_rej, correct_test_no_rej = calculate_value_without_rejection(\n",
        "                y_hat_proba_test, y_test, Vw_fp, Vw_fn, Vc\n",
        "            )\n",
        "            \n",
        "            # calculate theoretical threshold\n",
        "            k_fn = (-1) * (Vw_fn / Vc)\n",
        "            \n",
        "            # handles output to file\n",
        "            data_log.append(\n",
        "                f\"{Vr},{Vc},{Vw_fp},{Vw_fn},{k_fp},{k_fn},{t_fp},{t_fn},{value_test},{rej_test},{wrong_test},{correct_test},{e_fp},{e_fn},{value_test_opt},{rej_test_opt},{wrong_test_opt},{correct_test_opt},{value_test_no_rej},{wrong_test_no_rej},{correct_test_no_rej}\\n\"\n",
        "            )\n",
        "        \n",
        "        with open(rc_path, \"a\") as f:\n",
        "            for i in data_log:\n",
        "                f.write(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlHi5AI8SKAx"
      },
      "outputs": [],
      "source": [
        "#result file\n",
        "logfile_name = \"results\"\n",
        "\n",
        "# cost-based parameters\n",
        "Vr = 0.0\n",
        "Vc = 1.0\n",
        "\n",
        "Vw_list_fn = list(np.arange(0, -10.1, -1))\n",
        "Vw_list_fp = list(np.arange(0, -10.1, -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjrUV0I5ZQSq"
      },
      "outputs": [],
      "source": [
        "logits_val = np.load(data_folder  + confidencesToVal)\n",
        "y_val_df = pd.read_csv(data_folder + dataToVal)\n",
        "y_val = y_val_df[ground_truth_column].values\n",
        "\n",
        "logits_test = np.load(data_folder  + confidencesToTest)\n",
        "y_test_df = pd.read_csv(data_folder + dataToTest)\n",
        "y_test = y_test_df[ground_truth_column].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1RkiahOSl1v"
      },
      "outputs": [],
      "source": [
        "cost_based_analysis(logits_val, y_val, logits_test, y_test, resPath, logfile_name, Vr, Vc, Vw_list_fp, Vw_list_fn, 3, 3, 1, 1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "value_analysis_binary_github.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
